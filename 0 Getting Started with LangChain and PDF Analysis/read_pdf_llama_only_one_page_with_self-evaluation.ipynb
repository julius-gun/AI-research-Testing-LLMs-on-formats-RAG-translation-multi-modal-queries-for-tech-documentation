{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Evaluating model: llama3.2:1b\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Evaluating model: llama3.2\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Evaluating model: llama3.1\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Analysis Results\n",
      "====================\n",
      "\n",
      "Model: llama3.2:1b\n",
      "--------------------------------------------------\n",
      "Accuracy: 50.0% (2/4 correct answers)\n",
      "\n",
      "Question: At which flowrate of fertilizer in kg/min is it advised to use the fine application?\n",
      "Expected Answer: 40kg/min\n",
      "Model Response: I am very sure. It is advised to use the fine application when the flowrate is less than 40 kg/min, according to the spreading chart that provides this information for different working widths of the spreader.\n",
      "Self-Evaluation (Correct?): no\n",
      "Time taken: 30.08 seconds\n",
      "\n",
      "Question: What is the maximum operating angle of the coupling shaft?\n",
      "Expected Answer: 30 degrees\n",
      "Model Response: Based on the given context, I conclude that the maximum operating angle of the coupling shaft is 30° when lifted. \n",
      "\n",
      "The mention of \"when lifted\" suggests a specific position or range of operation, which typically indicates a limited working angle. In this case, it appears to be the maximum possible angle under these conditions.\n",
      "Self-Evaluation (Correct?): yes\n",
      "Time taken: 29.98 seconds\n",
      "\n",
      "Question: What materials are required to perform the tray test?\n",
      "Expected Answer: You'll need a measuring tape or ruler, a spirit level, 7 troughs, 7 graduated tubes, a funnel, a notebook, pen, calculator, this manual, and the software's instruction manual.\n",
      "Model Response: Based on the provided context, I am very sure that the following materials are required for performing the tray test:\n",
      "\n",
      "1. Measuring tape or ruler\n",
      "2. Spirit level\n",
      "3. 7 troughs\n",
      "4. 7 graduated tubes\n",
      "5. 1 funnel\n",
      "6. Notebook, pen and calculator\n",
      "Self-Evaluation (Correct?): yes\n",
      "Time taken: 37.45 seconds\n",
      "\n",
      "Question: What is the general formula for calculating the required flowrate of fertilizer in kg/min?\n",
      "Expected Answer: Working width (m) x Driving speed (km/h) x Application rate (kg/ha) / 600\n",
      "Model Response: The general formula for calculating the required flowrate of fertilizer in kg/min, based on the given context, appears to be:\n",
      "\n",
      "Flowrate (kg/min) = Working width (m) x Driving speed (km/h) x Application rate (kg/ha)\n",
      "\n",
      "This can be derived from the formula provided on page 600: \n",
      "\n",
      "Flowrate (kg/min) = Working width (m) x Driving speed (km/h) x Application rate (kg/ha)\n",
      "\n",
      "I am very sure that this is indeed the correct formula.\n",
      "Self-Evaluation (Correct?): no\n",
      "Time taken: 44.38 seconds\n",
      "\n",
      "\n",
      "Model: llama3.2\n",
      "--------------------------------------------------\n",
      "Accuracy: 100.0% (4/4 correct answers)\n",
      "\n",
      "Question: At which flowrate of fertilizer in kg/min is it advised to use the fine application?\n",
      "Expected Answer: 40kg/min\n",
      "Model Response: The flowrate at which it is advised to use the fine application is 40 kg/min.\n",
      "Self-Evaluation (Correct?): yes\n",
      "Time taken: 75.63 seconds\n",
      "\n",
      "Question: What is the maximum operating angle of the coupling shaft?\n",
      "Expected Answer: 30 degrees\n",
      "Model Response: The maximum operating angle of the coupling shaft when lifted and lowered is 30°.\n",
      "Self-Evaluation (Correct?): yes\n",
      "Time taken: 43.57 seconds\n",
      "\n",
      "Question: What materials are required to perform the tray test?\n",
      "Expected Answer: You'll need a measuring tape or ruler, a spirit level, 7 troughs, 7 graduated tubes, a funnel, a notebook, pen, calculator, this manual, and the software's instruction manual.\n",
      "Model Response: The relevant sentence for answering the question is:\n",
      "\n",
      "\"Material required: •measuring tape or ruler, •spirit level to set the troughs horizontal, •7 troughs, •7 graduated tubes, •1 funnel, •notebook, pen and calculator,\"\n",
      "Self-Evaluation (Correct?): yes\n",
      "Time taken: 67.56 seconds\n",
      "\n",
      "Question: What is the general formula for calculating the required flowrate of fertilizer in kg/min?\n",
      "Expected Answer: Working width (m) x Driving speed (km/h) x Application rate (kg/ha) / 600\n",
      "Model Response: According to the context, the general formula for calculating the required flowrate of fertilizer in kg/min is:\n",
      "\n",
      "flowrate (kg/min) = Working width (m) x Driving speed (km/h) x Application rate (kg/ha)\n",
      "Self-Evaluation (Correct?): yes\n",
      "Time taken: 65.98 seconds\n",
      "\n",
      "\n",
      "Model: llama3.1\n",
      "--------------------------------------------------\n",
      "Accuracy: 100.0% (4/4 correct answers)\n",
      "\n",
      "Question: At which flowrate of fertilizer in kg/min is it advised to use the fine application?\n",
      "Expected Answer: 40kg/min\n",
      "Model Response: It is advised to make use of the fine application if the flowrate is less than 40 kg/min.\n",
      "Self-Evaluation (Correct?): yes\n",
      "Time taken: 226.90 seconds\n",
      "\n",
      "Question: What is the maximum operating angle of the coupling shaft?\n",
      "Expected Answer: 30 degrees\n",
      "Model Response: The relevant sentence from the context is:\n",
      "\n",
      "\"The maximum operating angle of the coupling shaft is 30° when lifted and 30° when lowered.\"\n",
      "\n",
      "Therefore, my concise answer to your question is:\n",
      "\n",
      "The maximum operating angle of the coupling shaft is 30°.\n",
      "Self-Evaluation (Correct?): yes\n",
      "Time taken: 191.19 seconds\n",
      "\n",
      "Question: What materials are required to perform the tray test?\n",
      "Expected Answer: You'll need a measuring tape or ruler, a spirit level, 7 troughs, 7 graduated tubes, a funnel, a notebook, pen, calculator, this manual, and the software's instruction manual.\n",
      "Model Response: Here is the relevant sentence from the context:\n",
      "\n",
      "\"Material required\n",
      "•measuring tape or ruler,\n",
      "•spirit level to set the troughs horizontal,\n",
      "•7 troughs,\n",
      "•7 graduated tubes,\n",
      "•1 funnel,\n",
      "•notebook, pen and calculator,\n",
      "•this manual.\n",
      "•the instruction manual of the software.\"\n",
      "\n",
      "The materials required to perform the tray test are:\n",
      "\n",
      "Measuring tape or ruler\n",
      "Spirit level to set the troughs horizontal\n",
      "7 troughs\n",
      "7 graduated tubes\n",
      "1 funnel\n",
      "Notebook, pen, and calculator\n",
      "Self-Evaluation (Correct?): yes\n",
      "Time taken: 227.01 seconds\n",
      "\n",
      "Question: What is the general formula for calculating the required flowrate of fertilizer in kg/min?\n",
      "Expected Answer: Working width (m) x Driving speed (km/h) x Application rate (kg/ha) / 600\n",
      "Model Response: The general formula for calculating the required flowrate of fertilizer is:\n",
      "\n",
      "flowrate required (kg/min) = Working width (m) x Driving speed (km/h) x Application rate (kg/ha)\n",
      "\n",
      "This formula is explicitly stated at the end of the context, under \"Calculation\".\n",
      "Self-Evaluation (Correct?): yes\n",
      "Time taken: 186.65 seconds\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "import time\n",
    "from typing import Dict, List, Tuple\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class PDFAnalyzer:\n",
    "    def __init__(self, pdf_path: str):\n",
    "        \"\"\"Initialize the PDF analyzer with the path to the PDF file.\"\"\"\n",
    "        self.pdf_path = pdf_path\n",
    "        self.models = {\n",
    "            \"llama3.2:1b\": OllamaLLM(model=\"llama3.2:1b\"),\n",
    "            \"llama3.2\": OllamaLLM(model=\"llama3.2\"),\n",
    "            \"llama3.1\": OllamaLLM(model=\"llama3.1\")\n",
    "        }\n",
    "        \n",
    "        # Create a separate evaluator model\n",
    "        self.evaluator_model = OllamaLLM(model=\"llama3.2:1b\")\n",
    "        \n",
    "        # Format: question, then expected answers + page number inside a list\n",
    "        self.questions_and_answers = {\n",
    "            \"At which flowrate of fertilizer in kg/min is it advised to use the fine application?\": \n",
    "                [\"40kg/min\", 67],\n",
    "            \"What is the maximum operating angle of the coupling shaft?\": \n",
    "                [\"30 degrees\", 54],\n",
    "            \"What materials are required to perform the tray test?\": \n",
    "                [\"You'll need a measuring tape or ruler, a spirit level, 7 troughs, 7 graduated tubes, a funnel, a notebook, pen, calculator, this manual, and the software's instruction manual.\", 77],\n",
    "            \"What is the general formula for calculating the required flowrate of fertilizer in kg/min?\":\n",
    "                [\"Working width (m) x Driving speed (km/h) x Application rate (kg/ha) / 600\", 68]\n",
    "        }\n",
    "        \n",
    "        # Template for zero-shot learning\n",
    "        self.prompt_template = PromptTemplate(\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "            template=\"\"\"\n",
    "            Below is a Context from a technical manual. Please answer the question at the end based only on the context provided.\n",
    "            The context includes much unnecessary information. Therefore ignore tables. Include the relevant sentence in your answer, and only answer the question if you are very sure. \n",
    "            The answer should be concise and to the point. Don't just copy the context but answer in a manner that makes sense. Double-check your answer before submitting.\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "            End of Context.\n",
    "            Question: {question}\n",
    "\n",
    "            Answer: Let me analyze the provided context and answer your question...\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        # Improved evaluation template for more accurate assessment\n",
    "        self.evaluation_template = PromptTemplate(\n",
    "            input_variables=[\"question\", \"model_answer\", \"expected_answer\"],\n",
    "            template=\"\"\"\n",
    "            You are a precise evaluator. Compare these two answers and determine if they convey the same information:\n",
    "\n",
    "            Question: {question}\n",
    "            Model's answer: {model_answer}\n",
    "            Expected answer: {expected_answer}\n",
    "\n",
    "            Rules for evaluation:\n",
    "            1. The answers must convey the same core information\n",
    "            2. Units and numerical values must match exactly\n",
    "            3. For lists of items, all required items must be present\n",
    "            4. Minor differences in phrasing are acceptable\n",
    "            5. Additional information in the model's answer is acceptable as long as the core information is correct\n",
    "\n",
    "            Respond with ONLY 'yes' if the answers match according to these rules, or 'no' if they don't.\n",
    "            Do not provide any explanation.\n",
    "\n",
    "            Answer (yes/no):\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "    def load_pdf(self) -> List[dict]:\n",
    "        \"\"\"Load and process the PDF document.\"\"\"\n",
    "        try:\n",
    "            loader = PyPDFLoader(self.pdf_path)\n",
    "            pages = loader.load()\n",
    "            \n",
    "            # Process pages and keep track of page numbers\n",
    "            processed_pages = []\n",
    "            for page in pages:\n",
    "                content = page.page_content\n",
    "                page_num = page.metadata['page']\n",
    "                processed_pages.append({\n",
    "                    'content': content,\n",
    "                    'page': page_num\n",
    "                })\n",
    "            return processed_pages\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading PDF: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def get_page_content(self, pages: List[dict], target_page: int) -> str:\n",
    "        \"\"\"Get content for a specific page number.\"\"\"\n",
    "        for page in pages:\n",
    "            if page['page'] == target_page:\n",
    "                return f\"[Page {page['page']}] {page['content']}\"\n",
    "        return \"\"\n",
    "\n",
    "    def calculate_accuracy(self, results: List[Dict]) -> Tuple[float, int, int]:\n",
    "        \"\"\"Calculate accuracy metrics from results.\"\"\"\n",
    "        total_questions = len(results)\n",
    "        correct_answers = sum(1 for result in results if result['self_evaluation'] == 'yes')\n",
    "        accuracy = (correct_answers / total_questions) * 100 if total_questions > 0 else 0\n",
    "        return accuracy, correct_answers, total_questions\n",
    "\n",
    "    def run_model_evaluation(self) -> Dict:\n",
    "        \"\"\"Run evaluation across all models for given questions.\"\"\"\n",
    "        results = {}\n",
    "        pages = self.load_pdf()\n",
    "        \n",
    "        for model_name, model in self.models.items():\n",
    "            logger.info(f\"Evaluating model: {model_name}\")\n",
    "            model_results = []\n",
    "            \n",
    "            for question, expected_answer in self.questions_and_answers.items():\n",
    "                try:\n",
    "                    target_page = expected_answer[1] - 1\n",
    "                    page_content = self.get_page_content(pages, target_page)\n",
    "                    \n",
    "                    prompt = self.prompt_template.format(\n",
    "                        context=page_content,\n",
    "                        question=question\n",
    "                    )\n",
    "                    \n",
    "                    start_time = time.time()\n",
    "                    response = model.invoke(prompt)\n",
    "                    end_time = time.time()\n",
    "                    \n",
    "                    eval_prompt = self.evaluation_template.format(\n",
    "                        question=question,\n",
    "                        model_answer=response,\n",
    "                        expected_answer=expected_answer[0]\n",
    "                    )\n",
    "\n",
    "                    self_evaluation = self.evaluator_model.invoke(eval_prompt).strip().lower()\n",
    "                    \n",
    "                    model_results.append({\n",
    "                        'question': question,\n",
    "                        'expected_answer': expected_answer,\n",
    "                        'response': response,\n",
    "                        'time_taken': end_time - start_time,\n",
    "                        'self_evaluation': self_evaluation\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error with model {model_name} on question: {question}\")\n",
    "                    logger.error(str(e))\n",
    "                    model_results.append({\n",
    "                        'question': question,\n",
    "                        'expected_answer': expected_answer,\n",
    "                        'response': f\"Error: {str(e)}\",\n",
    "                        'time_taken': None,\n",
    "                        'self_evaluation': 'error'\n",
    "                    })\n",
    "            \n",
    "            results[model_name] = model_results\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def format_results(self, results: Dict) -> str:\n",
    "        \"\"\"Format the results into a readable report.\"\"\"\n",
    "        report = \"PDF Analysis Results\\n\" + \"=\"*20 + \"\\n\\n\"\n",
    "        # print all model results first \n",
    "        for model_name, model_results in results.items():\n",
    "            report += f\"Accuracy: {accuracy:.1f}% ({correct_answers}/{total_questions} correct answers). \"\n",
    "            report += f\"Model: {model_name}\\n\" + \"-\"*50 + \"\\n\\n\"\n",
    "        \n",
    "        for model_name, model_results in results.items():\n",
    "            # Calculate accuracy metrics\n",
    "            accuracy, correct_answers, total_questions = self.calculate_accuracy(model_results)\n",
    "            report += \"-\"*20 + \"\\n\\n\"\n",
    "            report += f\"Detailed Results\"\n",
    "            report += \"-\"*20 + \"\\n\\n\"\n",
    "            report += f\"Model: {model_name}\\n\" + \"-\"*50 + \"\\n\"\n",
    "            \n",
    "            for result in model_results:\n",
    "                report += f\"Question: {result['question']}\\n\"\n",
    "                report += f\"Expected Answer: {result['expected_answer'][0]}\\n\"\n",
    "                report += f\"Model Response: {result['response']}\\n\"\n",
    "                report += f\"Self-Evaluation (Correct?): {result['self_evaluation']}\\n\"\n",
    "                if result['time_taken']:\n",
    "                    report += f\"Time taken: {result['time_taken']:.2f} seconds\\n\"\n",
    "                report += \"\\n\"\n",
    "            \n",
    "            report += \"\\n\"\n",
    "            \n",
    "        return report\n",
    "\n",
    "def main():\n",
    "    # Initialize analyzer\n",
    "    pdf_path = \"PDF/EN-A148703540-2.pdf\"\n",
    "    analyzer = PDFAnalyzer(pdf_path)\n",
    "    \n",
    "    try:\n",
    "        # Run evaluation\n",
    "        results = analyzer.run_model_evaluation()\n",
    "        \n",
    "        # Format and display results\n",
    "        report = analyzer.format_results(results)\n",
    "        print(report)\n",
    "        \n",
    "        # Optionally save results to file\n",
    "        with open(\"analysis_results_one_page_input_with_self_evaluation.txt\", \"w\") as f:\n",
    "            f.write(report)\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in main execution: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

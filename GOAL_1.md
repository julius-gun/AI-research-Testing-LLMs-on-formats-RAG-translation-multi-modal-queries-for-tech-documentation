### Goal 1: Evaluate Machine-Readable Formats
 #### Models tested
 | Model             | Number of Parameters | Context Length |
|-------------------|----------------------|----------------|
| llama3.2:1b       | 1b                   | 128k           |
| llama3.2:3b       | 3b                   | 128k           |
| llama3.1          | 8b                   | 128k           |
| phi3:mini-128k    | 3.8b                 | 128k           |
| phi3:medium-128k  | 14b                  | 128k           |
| gemma2:9b (used only for evaluation)         | 9b                   | 8k           |

**Due to an error the following results are wrong. The results and plots will be updated soon:**
<p align="left">
  <img src="1 Evaluate Machine-Readable Formats for LLMs/1.1 Compare Formats/accuracy_analysis/accuracy_plot_phi3_mini-128k.png" alt="Accuracy Comparison for phi3 mini-128k" width="500"/>
  <br>
  <img src="1 Evaluate Machine-Readable Formats for LLMs/1.1 Compare Formats/accuracy_analysis/accuracy_plot_phi3_medium-128k.png" alt="Accuracy Comparison for phi3 medium-128k" width="500"/>
  <br>
  <img src="1 Evaluate Machine-Readable Formats for LLMs/1.1 Compare Formats/accuracy_analysis/accuracy_plot_llama3.2_1b.png" alt="Accuracy Comparison for llama3.2 1b" width="500"/>
  <br>
  <img src="1 Evaluate Machine-Readable Formats for LLMs/1.1 Compare Formats/accuracy_analysis/accuracy_plot_llama3.2.png" alt="Accuracy Comparison for llama3.2" width="500"/>
  <br>
  <img src="1 Evaluate Machine-Readable Formats for LLMs/1.1 Compare Formats/accuracy_analysis/accuracy_plot_llama3.1.png" alt="Accuracy Comparison for llama3.1" width="500"/>
  <br>
</p>

    